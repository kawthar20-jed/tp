{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXpNdqu4cv74",
        "outputId": "88542a22-80da-4019-cd84-0ec4216c202d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7iHbuLCc6De",
        "outputId": "0ae71256-128f-4d82-f383-a38d27eccb97"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le jeu de données\n",
        "data = pd.read_csv(\"movie_review[1].csv\")\n",
        "\n",
        "# Afficher les premières lignes pour vérification\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KXgUANIdUeP",
        "outputId": "da780833-4864-4892-bbda-375191725fe0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fold_id cv_tag  html_id  sent_id  \\\n",
            "0        0  cv000    29590        0   \n",
            "1        0  cv000    29590        1   \n",
            "2        0  cv000    29590        2   \n",
            "3        0  cv000    29590        3   \n",
            "4        0  cv000    29590        4   \n",
            "\n",
            "                                                text  tag  \n",
            "0  films adapted from comic books have had plenty...  pos  \n",
            "1  for starters , it was created by alan moore ( ...  pos  \n",
            "2  to say moore and campbell thoroughly researche...  pos  \n",
            "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
            "4  in other words , don't dismiss this film becau...  pos  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition des stop words et de la ponctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "\n"
      ],
      "metadata": {
        "id": "4yXrP5E1l7gN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    # Convertir le texte en minuscules\n",
        "    text = text.lower()\n",
        "\n",
        "\n",
        "\n",
        "    # Tokenisation du texte en mots\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Suppression des mots vides et de la ponctuation\n",
        "    filtered_words = [word for word in words if word not in stop_words and word not in punctuation]\n",
        "\n",
        "    # Reconstitution du texte prétraité\n",
        "    preprocessed_text = ' '.join(filtered_words)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Appliquer le prétraitement aux données textuelles\n",
        "data['Text_Preprocessed'] = data['text'].apply(preprocess_text)\n",
        "# Afficher les premières lignes du dataframe pour vérifier\n",
        "# Accéder à une cellule spécifique contenant le texte prétraité et l'imprimer\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sOXDNDi6yIL",
        "outputId": "3cbbc8d2-a1c1-45b8-e817-81ab1fa3460f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fold_id cv_tag  html_id  sent_id  \\\n",
            "0        0  cv000    29590        0   \n",
            "1        0  cv000    29590        1   \n",
            "2        0  cv000    29590        2   \n",
            "3        0  cv000    29590        3   \n",
            "4        0  cv000    29590        4   \n",
            "\n",
            "                                                text  tag  \\\n",
            "0  films adapted from comic books have had plenty...  pos   \n",
            "1  for starters , it was created by alan moore ( ...  pos   \n",
            "2  to say moore and campbell thoroughly researche...  pos   \n",
            "3  the book ( or \" graphic novel , \" if you will ...  pos   \n",
            "4  in other words , don't dismiss this film becau...  pos   \n",
            "\n",
            "                                   Text_Preprocessed  \n",
            "0  films adapted comic books plenty success wheth...  \n",
            "1  starters created alan moore eddie campbell bro...  \n",
            "2  say moore campbell thoroughly researched subje...  \n",
            "3  book `` graphic novel `` 500 pages long includ...  \n",
            "4                      words n't dismiss film source  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO2VRl2eAg8M",
        "outputId": "796985c4-211e-4f59-9b80-1c91efe0660f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "# Appliquer le prétraitement aux données textuelles et former la liste de listes de mots\n",
        "sentences = data['text'].apply(preprocess_text).tolist()\n"
      ],
      "metadata": {
        "id": "sHPHW6kvAiEe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkECU5SBAO4V",
        "outputId": "2cbd5dba-7dc6-4d4c-f6c5-050a5c6afb15"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde du modèle entraîné\n",
        "model.save(\"word2vec_model.bin\")"
      ],
      "metadata": {
        "id": "qWNRzHXABFR6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_review_vector(review):\n",
        "    # Tokenisation du texte en mots\n",
        "    words = nltk.word_tokenize(review.lower())\n",
        "\n",
        "    # Filtrage des mots vides et de la ponctuation\n",
        "    filtered_words = [word for word in words if word not in stop_words and word not in punctuation]\n",
        "\n",
        "    # Initialiser le vecteur moyen à zéro\n",
        "    review_vector = np.zeros(model.vector_size)\n",
        "\n",
        "    # Calcul de la somme des embeddings des mots présents dans le modèle\n",
        "    word_count = 0\n",
        "    for word in filtered_words:\n",
        "        if word in model.wv:\n",
        "            review_vector += model.wv[word]\n",
        "            word_count += 1\n",
        "\n",
        "    # Si au moins un mot dans la review est présent dans le modèle, diviser le vecteur moyen par le nombre de mots\n",
        "    if word_count != 0:\n",
        "        review_vector /= word_count\n",
        "\n",
        "    return review_vector"
      ],
      "metadata": {
        "id": "0vYXCt3xBHj1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Appliquer la fonction get_review_vector à chaque review dans le dataframe\n",
        "data['Review_Vector'] = data['text'].apply(get_review_vector)\n",
        "\n",
        "# Afficher les premières lignes du dataframe avec les vecteurs de reviews\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDHx7CUYBa8M",
        "outputId": "581c42f0-5a22-4888-a5be-d1f281fbeaf6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       fold_id cv_tag  html_id  sent_id  \\\n",
            "0            0  cv000    29590        0   \n",
            "1            0  cv000    29590        1   \n",
            "2            0  cv000    29590        2   \n",
            "3            0  cv000    29590        3   \n",
            "4            0  cv000    29590        4   \n",
            "...        ...    ...      ...      ...   \n",
            "64715        9  cv999    14636       20   \n",
            "64716        9  cv999    14636       21   \n",
            "64717        9  cv999    14636       22   \n",
            "64718        9  cv999    14636       23   \n",
            "64719        9  cv999    14636       24   \n",
            "\n",
            "                                                    text  tag  \\\n",
            "0      films adapted from comic books have had plenty...  pos   \n",
            "1      for starters , it was created by alan moore ( ...  pos   \n",
            "2      to say moore and campbell thoroughly researche...  pos   \n",
            "3      the book ( or \" graphic novel , \" if you will ...  pos   \n",
            "4      in other words , don't dismiss this film becau...  pos   \n",
            "...                                                  ...  ...   \n",
            "64715  that lack of inspiration can be traced back to...  neg   \n",
            "64716  like too many of the skits on the current inca...  neg   \n",
            "64717  after watching one of the \" roxbury \" skits on...  neg   \n",
            "64718   bump unsuspecting women , and . . . that's all .  neg   \n",
            "64719  after watching _a_night_at_the_roxbury_ , you'...  neg   \n",
            "\n",
            "                                       Text_Preprocessed  \\\n",
            "0      films adapted comic books plenty success wheth...   \n",
            "1      starters created alan moore eddie campbell bro...   \n",
            "2      say moore campbell thoroughly researched subje...   \n",
            "3      book `` graphic novel `` 500 pages long includ...   \n",
            "4                          words n't dismiss film source   \n",
            "...                                                  ...   \n",
            "64715    lack inspiration traced back insipid characters   \n",
            "64716  like many skits current incarnation _saturday_...   \n",
            "64717  watching one `` roxbury `` skits snl come away...   \n",
            "64718                         bump unsuspecting women 's   \n",
            "64719  watching _a_night_at_the_roxbury_ 'll left exa...   \n",
            "\n",
            "                                           Review_Vector  \n",
            "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "...                                                  ...  \n",
            "64715  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "64716  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "64717  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "64718  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "64719  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
            "\n",
            "[64720 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Diviser le dataset en ensembles d'entraînement et de test\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Afficher la taille des ensembles d'entraînement et de test\n",
        "print(\"Taille de l'ensemble d'entraînement :\", len(train_data))\n",
        "print(\"Taille de l'ensemble de test :\", len(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEQEdk3LCHwC",
        "outputId": "23d15a44-bea1-401f-e32d-b81e0f0f52b9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille de l'ensemble d'entraînement : 51776\n",
            "Taille de l'ensemble de test : 12944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Extraire les caractéristiques d'entrée (input features) et les étiquettes (labels)\n",
        "X_train = np.array(train_data['Review_Vector'].to_list())\n",
        "y_train = train_data['tag']\n",
        "\n",
        "X_test = np.array(test_data['Review_Vector'].to_list())\n",
        "y_test = test_data['tag']\n",
        "\n",
        "# Entraîner le modèle de régression logistique\n",
        "model = LogisticRegression(max_iter=1000)  # Vous pouvez ajuster les hyperparamètres selon vos besoins\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Faire des prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculer la précision du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Précision du modèle de régression logistique :\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxjGiXP7CbzH",
        "outputId": "f4ab3dbf-337d-416f-9b14-c71d5567eb5f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Précision du modèle de régression logistique : 0.507725587144623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculer les prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculer les différentes métriques d'évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Afficher les métriques d'évaluation\n",
        "print(\"Accuracy :\", accuracy)\n",
        "print(\"Precision :\", precision)\n",
        "print(\"Recall :\", recall)\n",
        "print(\"F1-score :\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N-1Nbq8CqRA",
        "outputId": "ca038de5-2d6e-498a-b826-f78d0945929f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.507725587144623\n",
            "Precision : 0.5028646402099018\n",
            "Recall : 0.507725587144623\n",
            "F1-score : 0.3561593879729367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDrjueZvCxrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}